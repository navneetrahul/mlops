{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a360d53",
   "metadata": {},
   "source": [
    "# End to End Model Development and Deployment"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3ed9f5be",
   "metadata": {},
   "source": [
    "Diabetics is a chronic disease that affects millions worldwide.Particularly we are intrested to analyze diabetes in female patients.\n",
    "\n",
    "**Problem Statement**\n",
    "Develop a machine learning model to predict diabetes in women and deplo it as a web app in StreamLit\n",
    "\n",
    "**Dataset Description**\n",
    "This is the Pima Indians Dataset from kaggle.com and has data about 768 women of Pisma heritage 21 years and above. This is an open source dataset.\n",
    "\n",
    "**Steps of modelling process**\n",
    "1. Import all libraries and view the data set.\n",
    "2. Do the data sanity check.\n",
    "3. Clean the data\n",
    "4. Perform Exploratory Data Analysis\n",
    "5. Preprocess the data for modelling\n",
    "6. Fit and evaluate Machine Learning models\n",
    "7. Optimize the best model\n",
    "8. Interpret the tuned model\n",
    "9. Prepare for deployment by creating a pipeline.\n",
    "10. Deploy in Streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27e592d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data manipulation and EDA libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# data preprocessing libraries\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# data modelling libraries\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# data metrics \n",
    "from sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score,roc_auc_score,roc_curve\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "# Model interpretation and deployment libraries\n",
    "import shap\n",
    "import pickle\n",
    "from sklearn.pipeline import Pipeline\n",
    "import streamlit as st\n",
    "print(\"All libraries are imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6668049d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"diabetes.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5a073375",
   "metadata": {},
   "source": [
    "**Attributes of the data**\n",
    "1. Pregnencies- The number of times the patient was pregnant\n",
    "2. Glucose- The serum glucose level of the patient\n",
    "3. BloodPressure- Duastolic blood pressure(mm of Hg)\n",
    "4. SkinThickness- Triceps fold skin thickness(mm)\n",
    "5. Insulin- The serum insulin level of the patient.\n",
    "6. BMI- Body Mass Index (weight/height**2) is a measure of obesity\n",
    "7. DiabetesPedigreeFunction- A genetic propensity towards diabetes base on family history\n",
    "8. Age- Age of the patient\n",
    "9. Outcome- The target variable with two levels(Yes/No)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ddf886",
   "metadata": {},
   "source": [
    "# Step2 : Data Sanity check\n",
    "- Get the basic info of the data.\n",
    "- Look for null values\n",
    "- Look for corrupted data\n",
    "- Get the data summary statistics (both numerical and categorical)\n",
    "- Look for erroneous values in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d88a3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the shape of the data\n",
    "data_shape=data.shape\n",
    "print(\"Rows =\",data_shape[0],\"\\nColumns =\",data_shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4245d96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the basic info\n",
    "info=data.info()\n",
    "\n",
    "# get the data type\n",
    "dtype=data.dtypes\n",
    "info,dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb49d716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for unique levels in categorical\n",
    "data.Outcome.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0546a6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the value counts for outcome\n",
    "data[\"Outcome\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85548839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for nulls and duplicates\n",
    "nulls=data.isnull().sum()\n",
    "dups=data.duplicated().sum()\n",
    "nulls,dups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55df347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look for corrupt characters in the data\n",
    "data[~data.applymap(np.isreal).any(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4c3cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics of numerical and categorical data\n",
    "num_stats=data.describe().T\n",
    "cat_stats=data.describe(include=\"O\").T\n",
    "print(num_stats)\n",
    "print(cat_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603ef495",
   "metadata": {},
   "source": [
    "**Data Summary**\n",
    "1. The dataset has 768 rows and 9 columns\n",
    "2. The dataset has 8 numerical variables(int 64 and float 64) and one categorical variable \n",
    "3. **The categorical variable outcome has 4 levels which needs to be cleaned and be reduced to 2 levels (Yes-1/No-0)**\n",
    "4. There are no missing values or duplicates\n",
    "5. There are no corrupt characters\n",
    "6. **There are many columns which have minimum value as 0 ie., physiologically not feasible, so we have to impute them with      column medians**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca833a8d",
   "metadata": {},
   "source": [
    "## Step 3: Data Cleaning Step\n",
    "- encode coategorical outcome variable\n",
    "- impute columns with minimum value 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0494f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the data\n",
    "df=data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d72ed53",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=[ 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']\n",
    "zerofill=lambda x:x.replace(0,x.median())\n",
    "df[cols]=df[cols].apply(zerofill,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afefed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for minimum values\n",
    "df[df.columns[:]].agg(\"min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0f36fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical encoding\n",
    "d={\"Yes\":1,\"Tested_Positive\":1,\"No\":0,\"Tested_Negative\":0}\n",
    "df[\"Outcome\"]=df[\"Outcome\"].map(d)\n",
    "df[\"Outcome\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef03848",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Step 4: Exloratory data analysis correlation matrix and heatmap\n",
    "df.hist()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82735c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create individual box plots and histplots\n",
    "def histplot_boxplot(data, feature, figsize=(12, 7), bins=None):\n",
    "    print('Univariate for ...', feature)\n",
    "    fig, (ax_box, ax_hist) = plt.subplots(nrows=2, sharex=True, figsize=figsize)\n",
    "    \n",
    "    sns.boxplot(data=data, x=feature, color='violet', ax=ax_box, showmeans=True)\n",
    "    sns.histplot(data=data, x=feature, ax=ax_hist, bins=bins) if bins else sns.histplot(data=data, x=feature, ax=ax_hist)\n",
    "    plt.axvline(data[feature].mean(), color='green', linestyle='--')  # Use mean instead of data[feature]\n",
    "    plt.axvline(data[feature].median(), color='black', linestyle='-')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede8fdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df is your DataFrame, iterate through numeric columns\n",
    "for col in df.select_dtypes(exclude='O').columns:\n",
    "    histplot_boxplot(data=df, feature=col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1799e9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_outliers={}\n",
    "for col in df.columns:\n",
    "    q1=df[col].quantile(0.25)\n",
    "    q3=df[col].quantile(0.75)\n",
    "    iqr=q3-q1\n",
    "    outliers=((df[col]<(q1-1.5*iqr))|(df[col]>(q3+1.5*iqr)))\n",
    "    num_outliers[col]=outliers.sum()\n",
    "num_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb9458a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# univariate barchart for categorical outcome\n",
    "plt.figure(figsize=(12,7))\n",
    "ax=sns.countplot(df[\"Outcome\"],color=\"orange\")\n",
    "for p in ax.patches:\n",
    "    x=p.get_bbox().get_points()[:,0]\n",
    "    y=p.get_bbox().get_points()[1,1]\n",
    "    ax.annotate(\"{:.2g}%\".format(y*100/len(df)),(x.mean(),y),ha=\"center\",va=\"bottom\")\n",
    "plt.title(\"Univariate Bar Chart for Outcome\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49184902",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e16bb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
    "       'BMI', 'DiabetesPedigreeFunction', 'Age']\n",
    "for col in cols:\n",
    "    print(\"Bivariates between outcome and {}\".format(col))\n",
    "    df.groupby(\"Outcome\")[col].mean().plot(kind=\"bar\",color=\"orange\")\n",
    "    plt.ylabel(col)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409e9a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df,hue=\"Outcome\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3c8d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.corr(),annot=True,cmap=\"Spectral\",vmax=+1,vmin=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b40db5d",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "1. Pregnancies,insulin,DiabetesPedigreeFunction and age are right skewed.\n",
    "2. BloodPressure, Insulin, SkinThickness, DiabetesPredigree function had many oultliers.\n",
    "3. Outliers counts have been obtained but we will not resolve these outliers.\n",
    "4. The Outcome variable is highly imbalanced with 65% having 0 and 35% having 1.\n",
    "5. Women with higher Pregnencies,Glucose,BMI,Age,DiabetesPedigree Function are more prone to diabetes. To confirm this we will use pairplots and heatmaps.\n",
    "6. Based on KDE plots the distribution of Pregnencies,Glucose, Age, Diabetes Pedigree Function are much different for the two outcome classes showing that they are risk factors of diabetes.\n",
    "7. Scatter plot shows string positive trend between glucose and Insulin, Glucose and BMI, Glucose and age. These may be risk factors of diabetes. We confirm with a heatmap.\n",
    "8. Heatmap shows that Glucose,BMI and Age are risk factors of Diabetes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344a1f85",
   "metadata": {},
   "source": [
    "### Step 5: Data Preprocessing\n",
    "- Seperate features and label\n",
    "- Do the label encoding \n",
    "- Solve for Data_imbalance\n",
    "- Train_test_split\n",
    "- Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765bff32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(data,label):\n",
    "    # Seperate the features and label\n",
    "    X=df.drop(\"Outcome\",axis=1)\n",
    "    y=df[\"Outcome\"]\n",
    "    # Solve data imbalance\n",
    "    sm=SMOTE()\n",
    "    X,y=sm.fit_resample(X,y)\n",
    "    # train test split\n",
    "    x_train,x_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42,stratify=y) # Stratify will maintain the ratio of 0 and 1 in train and test\n",
    "    return x_train,x_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3912717a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=process(df,label=\"Outcome\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bcf0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features\n",
    "sc=StandardScaler()\n",
    "x_train=sc.fit_transform(x_train) # fit is to get mean and std from the data\n",
    "                                  # transform to use that mean and std on the data\n",
    "                                  # only transform is used in x_test so that it used x_train mean and std to transform and not test\n",
    "x_test=sc.transform(x_test)        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef61f7da",
   "metadata": {},
   "source": [
    "**We have preprocessed the data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f357f0",
   "metadata": {},
   "source": [
    "### Step 6: Fit and Evaluate ML Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b50f1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a metrics function\n",
    "def print_metrics(y_test,y_pred,model_name):\n",
    "    print(\"Metrics for model...\",model_name)\n",
    "    print(\" \")\n",
    "    print(\"Accuracy Score=\",accuracy_score(y_test,y_pred))\n",
    "    print(\" \")\n",
    "    print(\"Recall Score=\",recall_score(y_test,y_pred))\n",
    "    print(\" \")\n",
    "    print(\"Precision Score=\",precision_score(y_test,y_pred))\n",
    "    print(\" \")\n",
    "    print(\"f1 Score=\",f1_score(y_test,y_pred))\n",
    "    print(\" \")\n",
    "    print(\"ROC AUC Score=\",roc_auc_score(y_test,y_pred))\n",
    "    print(\" \")\n",
    "    print(\"Confusion Matrix\")\n",
    "    print(confusion_matrix(y_test,y_pred))\n",
    "    print(\" \")\n",
    "    print(\"Classification Report\")\n",
    "    print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df1ee43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets print and evaluate a KNN model\n",
    "knn=KNeighborsClassifier()\n",
    "knn.fit(x_train,y_train)\n",
    "y_pred=knn.predict(x_test)\n",
    "print_metrics(y_test,y_pred,\"KNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc82d369",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('fivethirtyeight') # fivethirtyeight is the website used during presidential elections in USA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb034ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets optimize the neighbours to improve by drawing model complexity curves\n",
    "neighbors=np.arange(1,12)\n",
    "train_accuracies=np.empty(len(neighbors))\n",
    "test_accuracies=np.empty(len(neighbors))\n",
    "\n",
    "#enumerate over the neighbors\n",
    "for i,k in enumerate(neighbors):\n",
    "    knn=KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(x_train,y_train)\n",
    "    train_accuracies[i]=knn.score(x_train,y_train)\n",
    "    test_accuracies[i]=knn.score(x_test,y_test)\n",
    "\n",
    "# Plot the model complexity curves\n",
    "plt.plot(neighbors,train_accuracies,label=\"Training Metrics\")\n",
    "plt.plot(neighbors,test_accuracies,label=\"Test Metrics\")\n",
    "plt.legend()\n",
    "plt.title(\"Model Complexity Curves\")\n",
    "plt.xlabel(\"Number of Neighbors\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27c16a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refit KNN with k=9\n",
    "knn=KNeighborsClassifier(n_neighbors=9)\n",
    "knn.fit(x_train,y_train)\n",
    "y_pred=knn.predict(x_test)\n",
    "print_metrics(y_test,y_pred,\"KNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0001a942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit all models to get the best model to optimize\n",
    "clfs={\"logreg\":LogisticRegression(),\n",
    "    \"knn\":KNeighborsClassifier(),\n",
    "     \"naive bayes\":GaussianNB(),\n",
    "     \"decision tree\":DecisionTreeClassifier(),\n",
    "     \"rfc\":RandomForestClassifier(),\n",
    "     \"ABC\":AdaBoostClassifier(),\n",
    "     \"GBC\":GradientBoostingClassifier(),\n",
    "     \"SVM\":SVC(),\n",
    "     \"XGB\":XGBClassifier()}\n",
    "models_report=pd.DataFrame(columns=[\"Model Name\",\"Accuracy\",\"Recall\",\"Precision\",\"F1 Score\"])\n",
    "for clf,clf_name in list(zip(clfs.values(),clfs.keys())):\n",
    "    clf.fit(x_train,y_train)\n",
    "    y_pred=clf.predict(x_test)\n",
    "    print(\"Fitting the model ...\",clf_name)\n",
    "    t=pd.Series({\"Model Name\":clf_name,\n",
    "                 \"Accuracy\":accuracy_score(y_test,y_pred),\n",
    "                 \"Recall\":recall_score(y_test,y_pred),\n",
    "                 \"Precision\":precision_score(y_test,y_pred),\n",
    "                 \"F1 Score\":f1_score(y_test,y_pred)})\n",
    "    models_report=models_report.append(t,ignore_index=True)\n",
    "models_report=models_report.sort_values(by=\"F1 Score\",ascending=False)\n",
    "print(models_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6830f64c",
   "metadata": {},
   "source": [
    "### Step 7: Model Optimizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df28c6db",
   "metadata": {},
   "source": [
    "**Random Forest came out to be the best and we will optimize it.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc88dfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a RFC to the data \n",
    "rfc=RandomForestClassifier()\n",
    "rfc.fit(x_train,y_train)\n",
    "y_pred=rfc.predict(x_test)\n",
    "print_metrics(y_test,y_pred,\"RFC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb62fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for overfitting \n",
    "train_acc=rfc.score(x_train,y_train)\n",
    "test_acc=rfc.score(x_test,y_test)\n",
    "train_acc,test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4917e5",
   "metadata": {},
   "source": [
    "There appears to be overfitting which need to be considered and solved this could be because we balanced the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45bb21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3cb3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "param_dict={\"n_estimators\":range(100,1000,50),\n",
    "           \"min_samples_leaf\":range(1,5),\n",
    "           \"min_samples_split\":range(2,10,2),\n",
    "           \"max_depth\":range(10,100,5),\n",
    "           \"max_features\":[\"auto\",\"sqrt\",\"log2\"],\n",
    "           \"criterion\":[\"gini\",\"entropy\"]}\n",
    "n_folds=10\n",
    "rs=RandomizedSearchCV(estimator=rfc,param_distributions=param_dict,scoring=\"f1\",random_state=42,n_jobs=-1,n_iter=100,cv=n_folds)\n",
    "rs.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160d103f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47576b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a4b744",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d84fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for overfitting \n",
    "train_acc=rs.score(x_train,y_train)\n",
    "test_acc=rs.score(x_test,y_test)\n",
    "train_acc,test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f9df5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuned rfc object\n",
    "rfc_tuned=RandomForestClassifier(criterion='entropy', max_depth=70, max_features='log2',\n",
    "                       min_samples_split=4, n_estimators=950)\n",
    "rfc_tuned.fit(x_train,y_train)\n",
    "y_pred=rfc_tuned.predict(x_test)\n",
    "print_metrics(y_test,y_pred,\"rfc_tuned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2098d742",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc=rfc_tuned.score(x_train,y_train)\n",
    "test_acc=rfc_tuned.score(x_test,y_test)\n",
    "train_acc,test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a848abca",
   "metadata": {},
   "source": [
    "### Step 9: Prepare for deployment by creating a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c0e083",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4e64fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc=StandardScaler()\n",
    "model=RandomForestClassifier(criterion='entropy', max_depth=70, max_features='log2',\n",
    "                       min_samples_split=4, n_estimators=950)\n",
    "steps=[(\"scaler\",sc),(\"model\",model)]\n",
    "pipeline=Pipeline(steps) \n",
    "x_train,x_test,y_train,y_test=process(df,label=\"Outcome\")\n",
    "pipeline.fit(x_train,y_train)\n",
    "y_pred=pipeline.predict(x_test)\n",
    "print_metrics(y_test,y_pred,\"Pipeline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdce3524",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
